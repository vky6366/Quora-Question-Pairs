{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6277,"databundleVersionId":323734,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"path_to_zip_file = \"/kaggle/input/quora-question-pairs/train.csv.zip\"\ndirectory_to_extract_to = \"./\"\nimport zipfile\nwith zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n  zip_ref.extractall(directory_to_extract_to)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T19:32:48.134754Z","iopub.execute_input":"2025-04-10T19:32:48.135131Z","iopub.status.idle":"2025-04-10T19:32:48.998684Z","shell.execute_reply.started":"2025-04-10T19:32:48.135066Z","shell.execute_reply":"2025-04-10T19:32:48.997655Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom bs4 import BeautifulSoup","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T19:36:03.174938Z","iopub.execute_input":"2025-04-10T19:36:03.175537Z","iopub.status.idle":"2025-04-10T19:36:04.709893Z","shell.execute_reply.started":"2025-04-10T19:36:03.175509Z","shell.execute_reply":"2025-04-10T19:36:04.708958Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/working/train.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T19:36:15.349495Z","iopub.execute_input":"2025-04-10T19:36:15.350132Z","iopub.status.idle":"2025-04-10T19:36:16.999545Z","shell.execute_reply.started":"2025-04-10T19:36:15.350074Z","shell.execute_reply":"2025-04-10T19:36:16.998877Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def preprocess(r):\n    r = str(r).lower().strip()\n    r = r.replace('%','percent')\n    r = r.replace('$','dollar')\n    r = r.replace('₹','rupee')\n    r = r.replace('€','percent')\n    r = r.replace('@','percent')\n\n    r = r.replace('[math]','')\n    def simplify_number(text):\n        def repl(match):\n            num = int(match.group())\n            if num >= 1_000_000_000:\n                return f'{num//1_000_000_000}b'\n            elif num >= 1_000_000:\n                return f'{num//1_000_000}m'\n            elif num >= 1_000:\n                return f'{num//1_000}k'\n            return str(num)\n        \n        return re.sub(r'\\b\\d{4,}\\b', repl, text)\n        \n    r = simplify_number(r)\n\n    contractions = { \n        \"ain't\": \"am not\",\n        \"aren't\": \"are not\",\n        \"can't\": \"can not\",\n        \"can't've\": \"can not have\",\n        \"'cause\": \"because\",\n        \"could've\": \"could have\",\n        \"couldn't\": \"could not\",\n        \"couldn't've\": \"could not have\",\n        \"didn't\": \"did not\",\n        \"doesn't\": \"does not\",\n        \"don't\": \"do not\",\n        \"hadn't\": \"had not\",\n        \"hadn't've\": \"had not have\",\n        \"hasn't\": \"has not\",\n        \"haven't\": \"have not\",\n        \"he'd\": \"he would\",\n        \"he'd've\": \"he would have\",\n        \"he'll\": \"he will\",\n        \"he'll've\": \"he will have\",\n        \"he's\": \"he is\",\n        \"how'd\": \"how did\",\n        \"how'd'y\": \"how do you\",\n        \"how'll\": \"how will\",\n        \"how's\": \"how is\",\n        \"i'd\": \"i would\",\n        \"i'd've\": \"i would have\",\n        \"i'll\": \"i will\",\n        \"i'll've\": \"i will have\",\n        \"i'm\": \"i am\",\n        \"i've\": \"i have\",\n        \"isn't\": \"is not\",\n        \"it'd\": \"it would\",\n        \"it'd've\": \"it would have\",\n        \"it'll\": \"it will\",\n        \"it'll've\": \"it will have\",\n        \"it's\": \"it is\",\n        \"let's\": \"let us\",\n        \"ma'am\": \"madam\",\n        \"mayn't\": \"may not\",\n        \"might've\": \"might have\",\n        \"mightn't\": \"might not\",\n        \"mightn't've\": \"might not have\",\n        \"must've\": \"must have\",\n        \"mustn't\": \"must not\",\n        \"mustn't've\": \"must not have\",\n        \"needn't\": \"need not\",\n        \"needn't've\": \"need not have\",\n        \"o'clock\": \"of the clock\",\n        \"oughtn't\": \"ought not\",\n        \"oughtn't've\": \"ought not have\",\n        \"shan't\": \"shall not\",\n        \"sha'n't\": \"shall not\",\n        \"shan't've\": \"shall not have\",\n        \"she'd\": \"she would\",\n        \"she'd've\": \"she would have\",\n        \"she'll\": \"she will\",\n        \"she'll've\": \"she will have\",\n        \"she's\": \"she is\",\n        \"should've\": \"should have\",\n        \"shouldn't\": \"should not\",\n        \"shouldn't've\": \"should not have\",\n        \"so've\": \"so have\",\n        \"so's\": \"so as\",\n        \"that'd\": \"that would\",\n        \"that'd've\": \"that would have\",\n        \"that's\": \"that is\",\n        \"there'd\": \"there would\",\n        \"there'd've\": \"there would have\",\n        \"there's\": \"there is\",\n        \"they'd\": \"they would\",\n        \"they'd've\": \"they would have\",\n        \"they'll\": \"they will\",\n        \"they'll've\": \"they will have\",\n        \"they're\": \"they are\",\n        \"they've\": \"they have\",\n        \"to've\": \"to have\",\n        \"wasn't\": \"was not\",\n        \"we'd\": \"we would\",\n        \"we'd've\": \"we would have\",\n        \"we'll\": \"we will\",\n        \"we'll've\": \"we will have\",\n        \"we're\": \"we are\",\n        \"we've\": \"we have\",\n        \"weren't\": \"were not\",\n        \"what'll\": \"what will\",\n        \"what'll've\": \"what will have\",\n        \"what're\": \"what are\",\n        \"what's\": \"what is\",\n        \"what've\": \"what have\",\n        \"when's\": \"when is\",\n        \"when've\": \"when have\",\n        \"where'd\": \"where did\",\n        \"where's\": \"where is\",\n        \"where've\": \"where have\",\n        \"who'll\": \"who will\",\n        \"who'll've\": \"who will have\",\n        \"who's\": \"who is\",\n        \"who've\": \"who have\",\n        \"why's\": \"why is\",\n        \"why've\": \"why have\",\n        \"will've\": \"will have\",\n        \"won't\": \"will not\",\n        \"won't've\": \"will not have\",\n        \"would've\": \"would have\",\n        \"wouldn't\": \"would not\",\n        \"wouldn't've\": \"would not have\",\n        \"y'all\": \"you all\",\n        \"y'all'd\": \"you all would\",\n        \"y'all'd've\": \"you all would have\",\n        \"y'all're\": \"you all are\",\n        \"y'all've\": \"you all have\",\n        \"you'd\": \"you would\",\n        \"you'd've\": \"you would have\",\n        \"you'll\": \"you will\",\n        \"you'll've\": \"you will have\",\n        \"you're\": \"you are\",\n        \"you've\": \"you have\"\n        }\n\n    r_decontracted = []\n\n    for word in r.split():\n        if word in contractions:\n            word = contractions[word]\n\n        r_decontracted.append(word)\n    r = ' '.join(r_decontracted)\n    r = r.replace(\"'ve'\",\"have\")\n    r = r.replace(\"n't\",\"not\")\n    r = r.replace(\"'re\",\"are\")\n    r = r.replace(\"'ll'\",\"will\")\n\n\n    r = BeautifulSoup(r, \"html.parser\").get_text()\n\n    r = re.sub(r'\\W+', ' ', r).strip()\n\n    return r","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T19:56:21.510431Z","iopub.execute_input":"2025-04-10T19:56:21.510742Z","iopub.status.idle":"2025-04-10T19:56:21.528952Z","shell.execute_reply.started":"2025-04-10T19:56:21.510720Z","shell.execute_reply":"2025-04-10T19:56:21.527671Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"df['question1'] = df['question1'] .apply(preprocess)\ndf['question2'] = df['question2'] .apply(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:03:03.048217Z","iopub.execute_input":"2025-04-10T20:03:03.048713Z","iopub.status.idle":"2025-04-10T20:03:58.140493Z","shell.execute_reply.started":"2025-04-10T20:03:03.048684Z","shell.execute_reply":"2025-04-10T20:03:58.139507Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"df['q1_len'] = df['question1'].str.len()\ndf['q2_len'] = df['question2'].str.len()\ndf['q1_num_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\ndf['q2_num_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:07:11.296611Z","iopub.execute_input":"2025-04-10T20:07:11.296946Z","iopub.status.idle":"2025-04-10T20:07:12.482242Z","shell.execute_reply.started":"2025-04-10T20:07:11.296923Z","shell.execute_reply":"2025-04-10T20:07:12.481357Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def common_words(row):\n    w1 = set(map(lambda word: word.lower().strip(),row['question1'].split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(),row['question2'].split(\" \")))\n    return len(w1 & w2)\n\ndf['common_words'] = df.apply(common_words,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:16:00.002066Z","iopub.execute_input":"2025-04-10T20:16:00.002438Z","iopub.status.idle":"2025-04-10T20:16:06.875621Z","shell.execute_reply.started":"2025-04-10T20:16:00.002414Z","shell.execute_reply":"2025-04-10T20:16:06.874709Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"def total_words(row):\n    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))\n    return (len(w1) + len(w2))\n\ndf['total_words'] = df.apply(total_words,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:21:18.607068Z","iopub.execute_input":"2025-04-10T20:21:18.607452Z","iopub.status.idle":"2025-04-10T20:21:24.345562Z","shell.execute_reply.started":"2025-04-10T20:21:18.607428Z","shell.execute_reply":"2025-04-10T20:21:24.344531Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"df['word_share'] = round(df['common_words']/df['total_words'],2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:23:13.577285Z","iopub.execute_input":"2025-04-10T20:23:13.577609Z","iopub.status.idle":"2025-04-10T20:23:13.604212Z","shell.execute_reply.started":"2025-04-10T20:23:13.577588Z","shell.execute_reply":"2025-04-10T20:23:13.603203Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\ndef fetch_token_features(row):\n    q1 = row['question1']\n    q2 = row['question2']\n\n    con = 0.00001\n\n    stop_words = stopwords.words(\"english\")\n\n    token_features = [0.0]*8\n    q1_tokens = q1.split()\n    q2_tokens = q2.split()\n\n    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n        return token_features\n\n    q1_words = set([word for word in q1_tokens if word not in stop_words])\n    q2_words = set([word for word in q2_tokens if word not in stop_words])\n    \n    q1_stops = set([word for word in q1_tokens if word in stop_words])\n    q2_stops = set([word for word in q2_tokens if word in stop_words])\n\n    common_word_count = len(q1_words.intersection(q2_words))\n    common_stop_count = len(q1_stops.intersection(q2_stops))\n    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n\n    token_features[0] = common_word_count / (min(len(q1_words),len(q2_words)) + con)\n    token_features[1] = common_word_count / (max(len(q1_words),len(q2_words)) + con)\n    token_features[2] = common_stop_count / (min(len(q1_words),len(q2_words)) + con)\n    token_features[3] = common_stop_count / (max(len(q1_words),len(q2_words)) + con)\n    token_features[4] = common_token_count / (min(len(q1_words),len(q2_words)) + con)\n    token_features[5] = common_token_count / (max(len(q1_words),len(q2_words)) + con)\n    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n\n    return token_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:40:39.816995Z","iopub.execute_input":"2025-04-10T20:40:39.817330Z","iopub.status.idle":"2025-04-10T20:40:39.827909Z","shell.execute_reply.started":"2025-04-10T20:40:39.817308Z","shell.execute_reply":"2025-04-10T20:40:39.826902Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"token_features = df.apply(fetch_token_features,axis=1)\ndf['cwc_min'] = list(map(lambda x: x[0],token_features))\ndf['cwc_max'] = list(map(lambda x: x[1],token_features))\ndf['csc_min'] = list(map(lambda x: x[2],token_features))\ndf['csc_min'] = list(map(lambda x: x[3],token_features))\ndf['ctc_min'] = list(map(lambda x: x[4],token_features))\ndf['ctc_min'] = list(map(lambda x: x[5],token_features))\ndf['last_word_eq'] = list(map(lambda x: x[6],token_features))\ndf['first_word_eq'] = list(map(lambda x: x[7],token_features))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:40:40.372313Z","iopub.execute_input":"2025-04-10T20:40:40.372670Z","iopub.status.idle":"2025-04-10T20:42:18.424705Z","shell.execute_reply.started":"2025-04-10T20:40:40.372646Z","shell.execute_reply":"2025-04-10T20:42:18.423326Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"!pip install distance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T20:58:44.576759Z","iopub.execute_input":"2025-04-10T20:58:44.577082Z","iopub.status.idle":"2025-04-10T20:58:53.532651Z","shell.execute_reply.started":"2025-04-10T20:58:44.577060Z","shell.execute_reply":"2025-04-10T20:58:53.531281Z"}},"outputs":[{"name":"stdout","text":"Collecting distance\n  Downloading Distance-0.1.3.tar.gz (180 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: distance\n  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16256 sha256=4efef8b8830a334fe26cb269254bc5615822e651e3db28043500ba95217495f6\n  Stored in directory: /root/.cache/pip/wheels/fb/cd/9c/3ab5d666e3bcacc58900b10959edd3816cc9557c7337986322\nSuccessfully built distance\nInstalling collected packages: distance\nSuccessfully installed distance-0.1.3\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import distance\n\ndef fetch_length_features(row):\n    q1 = row['question1']\n    q2 = row['question2']\n\n    length_features = [0.0] * 3\n\n    q1_tokens = q1.split()\n    q2_tokens = q2.split()\n\n    # Fix logic: should be `or len(q2_tokens) == 0`\n    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n        return length_features\n\n    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n    length_features[1] = (len(q1_tokens) + len(q2_tokens)) / 2\n\n    strs = list(distance.lcsubstrings(q1, q2))\n    if len(strs) > 0:\n        length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n    else:\n        length_features[2] = 0.0\n\n    return length_features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:13:37.592166Z","iopub.execute_input":"2025-04-10T21:13:37.592564Z","iopub.status.idle":"2025-04-10T21:13:37.604262Z","shell.execute_reply.started":"2025-04-10T21:13:37.592538Z","shell.execute_reply":"2025-04-10T21:13:37.602699Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"length_features = df.apply(fetch_length_features,axis=1)\n\ndf['abs_len_diff'] = list(map(lambda x: x[0],length_features))\ndf['mean_len'] = list(map(lambda x:x[1],length_features))\ndf['longest_subtr_ratio'] = list(map(lambda x: x[2],length_features))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:13:39.401907Z","iopub.execute_input":"2025-04-10T21:13:39.402430Z","iopub.status.idle":"2025-04-10T21:17:41.650380Z","shell.execute_reply.started":"2025-04-10T21:13:39.402286Z","shell.execute_reply":"2025-04-10T21:17:41.649395Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"df.to_csv('preprocessed1.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T21:19:41.577139Z","iopub.execute_input":"2025-04-10T21:19:41.577685Z","iopub.status.idle":"2025-04-10T21:19:49.663370Z","shell.execute_reply.started":"2025-04-10T21:19:41.577655Z","shell.execute_reply":"2025-04-10T21:19:49.662417Z"}},"outputs":[],"execution_count":62}]}